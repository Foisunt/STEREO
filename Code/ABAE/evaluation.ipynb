{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import codecs\n",
    "\n",
    "from pathlib import Path\n",
    "from operator import add\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "#tf.sysconfig.get_build_info()\n",
    "\n",
    "\n",
    "from model import create_model\n",
    "from reader import get_vocab\n",
    "from argParseDummy import args\n",
    "from useABAE import loadModel, applyABAE, loadAspectWords, loadInfAspectsDict\n",
    "\n",
    "args()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGuiMethod():\n",
    "    import os,sys,inspect\n",
    "    currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "    parentdir = os.path.dirname(currentdir) \n",
    "    sys.path.insert(0,parentdir) \n",
    "    from GuiAskUser import callEvalABAE\n",
    "    return callEvalABAE #lambda x,y:[0]*len(y)\n",
    "\n",
    "def evalAllModels(sentences_path, modelNames_list, apaNonApa = \"APA\"):\n",
    "    models = []\n",
    "    infDicts = []\n",
    "    embDict = {\"cord\":args.cordEmb_path, \"extr\":args.extrEmb_path, \"extO\":args.extOthEmb_path}\n",
    "    vocabPathDict = {\"cord\":args.cordVocabDict_path, \"extr\":args.extrVocabDict_path, \"extO\":args.extOthVocabDict_path}\n",
    "    vocabDict = {}\n",
    "    for key in vocabPathDict:\n",
    "        vocabDict[key]=get_vocab(vocab_path = vocabPathDict[key])\n",
    "    for modelName in modelNames_list:\n",
    "        print(\"loading: \"+modelName)\n",
    "        infDicts.append(loadInfAspectsDict(args, modelName)) \n",
    "        models.append(loadModel(args, vocabDict[modelName[:4]], embDict[modelName[:4]], modelName, int(modelName[-2:])))\n",
    "    print(\"finished loading models and inferred aspects\")\n",
    "    \n",
    "    assert len(models) == len(modelNames_list)\n",
    "\n",
    "    correctAnswers = [0]*len(models)\n",
    "    \n",
    "    evalSentences = codecs.open(sentences_path, 'r', 'utf-8')\n",
    "    gui = getGuiMethod()\n",
    "    j = 0\n",
    "    for sen in evalSentences:\n",
    "        if sen == \" \\n\" or sen == \" \\r\\n\": continue\n",
    "        aspectList = []\n",
    "        for i,name in enumerate(modelNames_list):\n",
    "            pt = applyABAE(sen, models[i], vocabDict[name[:4]])\n",
    "            aspectNumber = np.argsort(pt)[-1]\n",
    "            aspectName = infDicts[i][aspectNumber]\n",
    "            aspectList.append(aspectName)\n",
    "\n",
    "        res = gui(sen, aspectList)\n",
    "        \n",
    "        correctAnswers = list(map(add, correctAnswers, res))\n",
    "        \n",
    "        for i,name in enumerate(modelNames_list):\n",
    "            evalLogPath = args.out_dir_path  / name / (\"evalLog\"+apaNonApa)\n",
    "            tmpFile = codecs.open(evalLogPath, \"a\", \"utf-8\")\n",
    "            tmpFile.write(str(j)+\": \"+ str(res[i]) + \"\\n\")\n",
    "            tmpFile.close()\n",
    "        j+=1\n",
    "    \n",
    "    resultFile_path = args.out_dir_path / (\"evalResults\"+apaNonApa)\n",
    "    resultFile = codecs.open(resultFile_path, \"w\", \"utf-8\")\n",
    "    for i,modelName in enumerate(modelNames_list):\n",
    "        resultFile.write(modelName+\": \"+str(correctAnswers[i])+\" \\n\")\n",
    "    resultFile.close()\n",
    "        \n",
    "    return correctAnswers\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eval 100 apa sentences on 15 models\n",
    "evalAllModels(args.evalSenApa_path, [\"cordModelExtOth15\", \"cordModelExtOth30\", \"cordModelExtOth60\",\n",
    "                                  \"cordModelExtr15\", \"cordModelExtr30\", \"cordModelExtr60\", \n",
    "                                  \"extOthModelExtOth15\", \"extOthModelExtOth30\", \"extOthModelExtOth60\", \n",
    "                                  \"extOthModelExtr15\", \"extOthModelExtr30\", \"extOthModelExtr60\", \n",
    "                                  \"extrModelExtr15\", \"extrModelExtr30\", \"extrModelExtr60\"], \n",
    "                                    apaNonApa = \"APA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval 100 non_apa sentences on 15 models\n",
    "evalAllModels(args.evalSenNonApa_path, [\"cordModelExtOth15\", \"cordModelExtOth30\", \"cordModelExtOth60\",\n",
    "                                  \"cordModelExtr15\", \"cordModelExtr30\", \"cordModelExtr60\", \n",
    "                                  \"extOthModelExtOth15\", \"extOthModelExtOth30\", \"extOthModelExtOth60\", \n",
    "                                  \"extOthModelExtr15\", \"extOthModelExtr30\", \"extOthModelExtr60\", \n",
    "                                  \"extrModelExtr15\", \"extrModelExtr30\", \"extrModelExtr60\"], \n",
    "                                    apaNonApa = \"NonAPA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
